# app.py
import gradio as gr
from my_rag.web_catch import TavilyWebSearch
from my_rag.embedding import build_vector_store, get_retriever
from my_rag.core_chain import build_qa_chain

chain = None

def init_chain(topic: str):
    global chain
    if chain is None:
        print(f"ğŸ”„ é¦–æ¬¡æœç´¢ï¼š{topic}")
        docs = TavilyWebSearch().load_docs(topic)
        vector_store = build_vector_store(docs, collection_name="gradio")
        chain = build_qa_chain(get_retriever(vector_store, top_k=4))
    return chain

def chat(message, history):
    """
    å…ˆç¡®ä¿é“¾å·²åˆå§‹åŒ–ï¼Œå†å›ç­”
    """
    current_chain = init_chain(message)
    return current_chain.invoke({"question": message})["answer"]

demo = gr.ChatInterface(
    fn=chat,
    title="SmartRAG Â· ä¸‡èƒ½é—®ç­”",
    description="è¾“å…¥ä»»ä½•ä¸»é¢˜ï¼Œæˆ‘ä¼šå®æ—¶æœç´¢å¹¶å›ç­”ï¼"
)

if __name__ == "__main__":
    demo.launch()